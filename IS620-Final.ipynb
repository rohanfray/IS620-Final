{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Loading of Data from our data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cPickle as pickle\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = pickle.load(open('test4','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "330071"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we have a list of 330k reviews composing the 250 closest businesses around 30 universities (see https://www.yelp.com/academic_dataset for more info).  In our previous step we created the this list of jsons from the overall dataset, removing items that dealt with users and businesses and keeping only records that dealt with reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'business_id': u'jTPr0dFk2JgGYdDiIGro3Q',\n",
       " u'date': u'2007-12-11',\n",
       " u'review_id': u'sVI08gDOu79XzELwaRDiQw',\n",
       " u'stars': 5,\n",
       " u'text': u'After enduring years of crappy, undercooked, bad pizza in and around Ann Arbor (a la pizza house, cottage inn, and the like), Silvio\\'s brings real pizza to town. Real pizza should be thin, have a crispy, bubbly, sourdough crust and be full of flavor, not grease, and this is the only place to get it.\\n\\nDon\\'t be fooled by the \"organic\" part of the name, it really should be called \"Silvio\\'s Italian Pizza\"\\n\\nBeware though, the more toppings you get on this pizza, the less well it cooks all the way through, and the less of a full pizza experience you get. The Margherita is a little light on the cheese, my only complaint.',\n",
       " u'type': u'review',\n",
       " u'user_id': u'NNFVXXEkb9Ur2ihVk_lW7A',\n",
       " u'votes': {u'cool': 0, u'funny': 0, u'useful': 0}}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Each item has the id for the business, user and review as well as the type and the date that this was created.  There is also the votes item which is a measure of how cool, funny, or useful other users found this review. The relevant fields for us however are text and stars (review score on a 1 to 5 scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Sentiment to predict Review Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to use the sentiment of the review text to predict the score of the review.  For that we will use the VADER sentiment package and then train a naive Bayes classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hutto, C.J. & Gilbert, E.E. (2014). VADER: A Parsimonious Rule-based Model for\n",
    "Sentiment Analysis of Social Media Text. Eighth International Conference on\n",
    "Weblogs and Social Media (ICWSM-14). Ann Arbor, MI, June 2014."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentAnalyzer\n",
    "from nltk.sentiment.util import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import nltk.sentiment.vader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'compound': -0.7437, 'neg': 0.078, 'neu': 0.889, 'pos': 0.033}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid.polarity_scores(f[11]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now note that we will not be cleaning or formatting the text because punctuations and capital letters have sentiment meaning.  Exclamation points and words that are in all capital letters can show an increased magnitude in the sentiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sklearn.cross_validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset,testset = sklearn.cross_validation.train_test_split(f,random_state=620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "247553"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82518"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of size and speed considerations, we will reduce the sets to 10% of their original size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainset = [ trainset[i] for i in sorted(random.sample(xrange(len(trainset)), 24755)) ]\n",
    "testset = [ testset[i] for i in sorted(random.sample(xrange(len(testset)), 8251)) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24755"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8251"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def features(review):\n",
    "    return sid.polarity_scores(review['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first try a Naive Bayes classifier, but since features are not factors, this may not be very accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trainfeatures = [(features(n), n['stars']) for n in trainset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "testfeatures = [(features(n), n['stars']) for n in testset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(trainfeatures)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.354623681978\n"
     ]
    }
   ],
   "source": [
    "print(nltk.classify.accuracy(clf, testfeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                     neg = 0.113               1 : 5      =     35.3 : 1.0\n",
      "                     neg = 0.135               1 : 4      =     32.6 : 1.0\n",
      "                     neg = 0.148               1 : 4      =     30.0 : 1.0\n",
      "                     pos = 0.024               1 : 4      =     28.5 : 1.0\n",
      "                     pos = 0.037               1 : 4      =     26.0 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf.show_most_informative_features(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try a Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfclf = RandomForestClassifier(n_jobs=2, n_estimators=3, max_features=\"auto\",random_state=620)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rfFeatures(review):\n",
    "    return sid.polarity_scores(review['text']).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_rf_1 = np.array([(rfFeatures(n)) for n in trainset])\n",
    "train_rf_2 = np.array([n['stars'] for n in trainset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_rf_1 = np.array([(rfFeatures(n)) for n in testset])\n",
    "test_rf_2 = np.array([n['stars'] for n in testset])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=3, n_jobs=2,\n",
       "            oob_score=False, random_state=620, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf.fit(train_rf_1,train_rf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_rf_pred = rfclf.predict(test_rf_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_rf_2, test_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x66470f60>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUwAAAEpCAYAAAD4Vxu2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x65ce42e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.RdPu)\n",
    "plt.title(\"Confusion Matrix for RandomForest classifier\")\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(len(set(test_rf_2)))\n",
    "plt.xticks(tick_marks, np.arange(1,6))\n",
    "plt.yticks(tick_marks, np.arange(1,6))\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30238758938310506"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_rf_2, test_rf_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          1       0.28      0.41      0.33       686\n",
      "          2       0.16      0.21      0.18       849\n",
      "          3       0.19      0.20      0.20      1580\n",
      "          4       0.40      0.34      0.37      2893\n",
      "          5       0.35      0.33      0.34      2243\n",
      "\n",
      "avg / total       0.31      0.30      0.31      8251\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_rf_2,test_rf_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.16513562,  0.21771897,  0.21449982,  0.40264559])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfclf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
